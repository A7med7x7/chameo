# {{ project_name }}

Welcome! This project is designed to help you **run reproducible ML experiments on Chameleon Cloud** , follow the guide below in order to know how to use this generated project. 

## Purpose of this README

It guides you through how to **provision resources, create, and configure servers using notebooks, and setup your environment** on Chameleon Cloud.  

>[!TIP]
> If you are looking for instructions on **how to generate this project** from the template generator, head to the **[main README](https://github.com/A7med7x7/chameo/blob/dev/README.md)**.

### Prerequisites

- You must have a [Chameleon Cloud](https://chameleoncloud.org) account. 
- You should have already configured SSH keys at the Chameleon site that you plan to use, e.g. following [Hello, Chameleon](https://teaching-on-testbeds.github.io/hello-chameleon/).

## Provisioning resources on Chameleon Cloud
>[!IMPORTANT]
> This guide start right after having a [reservation](https://chameleoncloud.readthedocs.io/en/latest/technical/reservations/gui_reservations.html), for a virtual machine or bare metal server, we recommend ideally to name your reservation leases with the 
> project name {{ project_name }} prefix. if not, it shouldn't be a big issue you will just need to manually enter your lease name later in the create server notebook no 1. 


The `chi` directory in your newly created project automates setting up data buckets, bringing up compute instances, and if you select notebook in `env_setup_mode`, it can will also help in launching a fully configured Jupyter environment with MLFlow experiment tracking for your machine learning experiments.

In [Chameleon JupyterHub](https://jupyter.chameleoncloud.org/hub/), clone your new project and open the `chi` directory.

```sh 
git clone {{ repo_url }} {{ project_name }}
```

### 1. First run only: Create object store buckets

At the beginning of your project you will 
1. **Create containers in Chameleon's object store**, 
to hold datasets, metrics, and artifacts from experiment runs.
unlike data saved to the ephemeral local disk of the compute instance, this data will persist beyond
the lifetime of the compute instance.
2. **Create neccessary crednetials**. if we want some of the tools we are going to use using (e.g rclone and MLflow) to be able to send and 
retrieve data from our object store we need to create application credentials or EC2 credentials that allows a script or application to authenticate to the object store.  
Inside the `chi` directory, run the notebook [`0_create_buckets.ipynb`](chi/0_create_buckets.ipynb) to create these buckets.                                                                

### 2. Launching a compute instance

When you need to work on your project, you will launch a compute instance on Chameleon Cloud.

First, you will [reserve an instance](https://chameleoncloud.readthedocs.io/en/latest/technical/reservations/gui_reservations.html). Use your project name as a prefix for your lease name.
(e.g {{ project_name }})-gpu-p100-ahmed
Then, to provision your server and configure it for your project, you will run:

{% if chameleon_site == 'KVM@TACC' and 'cpu' in gpu_type %}
- [`chi/1_create_server.ipynb`](chi/1_create_server.ipynb)
{% endif %}

{% if chameleon_site == 'KVM@TACC' and 'nvidia' in gpu_type %}
- [`chi/1_create_server_nvidia.ipynb`](chi/1_create_server_nvidia.ipynb)
{% endif %}

{% if chameleon_site in ['CHI@TACC', 'CHI@UC'] and 'amd' in gpu_type %}
- [`chi/1_create_server_amd.ipynb`](chi/1_create_server_amd.ipynb)
{% endif %}

{% if chameleon_site in ['CHI@TACC', 'CHI@UC'] and 'cpu' in gpu_type %}
- [`chi/1_create_server_cpu.ipynb`](chi/1_create_server_cpu.ipynb)
{% endif %}

{% if chameleon_site in ['CHI@TACC', 'CHI@UC'] and 'nvidia' in gpu_type %}
- [`chi/1_create_server_nvidia.ipynb`](chi/1_create_server_nvidia.ipynb)
{% endif %}

---

3. ### Configure and start your Jupyter environment

{% if env_setup_mode == 'ssh' and setup_mode != 'Basic' %}

On your computer instance (SSH-ing from your local machine via shell), generate the `.env` file required for docker compose:
From your **home directory** (`~`), run:

```sh
bash ./{{ project_name }}/scripts/generate_env.sh
```

you will be prompted to enter your HuggingFace Token,
after inputting, you should see something like:

`✅ The .env file has been generated successfully at : /home/cc/.env`
{% else %}

Open the Jupyter [notebook]({{ project_name }}/chi/1_create_server.ipynb
) in the chi directory inside your project:

Follow the instructions in the notebook to generate the .env file and configure your docker compose environment.

This approach is fully browser-based and guided, so you don’t need to SSH.
{% endif %}

---

### 3.5.  (Optional) Add your Python dependencies

Before building your Jupyter environment, you can include any third-party python dependencies by editing:
your [requirements.txt]({{ project_name }}/docker/requirements.txt) file. 
Inside this file it might look something like this. 
```txt 
package0 
package1==1.5.0
```
- To add a package: simply add it to the list in new line (e.g. LightGBM) or (LightGBM==4.6.0).
- To remove a package: delete its line.
- To update a version: change the version number.

---
### 4. Run your containerized environment 
From your **home directory** (`~`), run:
{% if "nvidia" in gpu_type or "cpu in gpu_type"%}
```sh
docker compose --env-file ~/.env -f {{ project_name }}/docker/docker-compose.yml up -d --build
```
{% endif %}

{% if "amd" in gpu_type%}
for amd 
```sh
docker compose --env-file ~/.env -f {{ project_name }}/docker/docker-compose-amd.yml up -d --build
```
{% endif %}
---

### 4.5 Login to Jupyter Lab and MLFlow UI

after your build finished, with the output 

```sh
[+] Running 5/5
 ✔ docker-jupyter          Built                                                                                                             
 ✔ docker-mlflow           Built                                                                                                             
 ✔ Network docker_default  Created                                                                                                           
 ✔ Container mlflow        Started                                                                                                     
 ✔ Container jupyter       Started        
 ```

you can access your Jupyter Lab and MLflow UI 
1. Access your jupyter: you can grab the token from running image using the command:

    ```sh
    docker exec jupyter jupyter server list | tail -n 1 | cut -f1 -d" " | sed "s/localhost/$(curl -s ifconfig.me)/"
    ```

    Open the printed URL in your browser.
2. Access MLflow UI 

    ```sh
    echo "http://$(curl -s ifconfig.me):$(docker port mlflow 8000 | cut -d':' -f2)"
    ```
    
Open this URL in your browser to see your experiments and logs.

### 5  Stop the Containerized Environment

If you’d like to pause your environment, you can stop the running containers with the command:
{% if "nvidia" in gpu_type or "cpu in gpu_type"%}
```sh
docker compose --env-file ~/.env -f {{ project_name }}/docker/docker-compose.yml down
```
{% endif %}

{% if "amd" in gpu_type %}
for amd 
```sh
docker compose --env-file ~/.env -f {{ project_name }}/docker/docker-compose-amd.yml down
```
{% endif %}

This will stop and remove the containers, but all your data in mounted volumes will remain safe.
When you want to restart later, simply run the docker compose up command again (see Step 4).

### 5.5 pushing code to GitHub 
once you have completed your first experiment run, you can push your code to GitHub. We've pre-installed the GitHub CLI in your container to make this easy.
First, sync your account by running this command
```sh
gh auth login --hostname github.com --git-protocol https --web <<< $'Y\n'
```
follow the instruction and you are ready to git push

---

### 6. Clean Up Resources

When finished, delete your server to free up resources.

**In Chameleon JupyterHub, open and run:**

- [`chi/3_delete_resources.ipynb`](chi/3_delete_resources.ipynb)